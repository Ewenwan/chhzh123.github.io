---
layout: post
title: TVM - GEMM优化
tags: [dl, tvm]
---

本文记录如何使用TVM v0.6在CPU上优化GEMM，节选自[TVM官方教程](https://docs.tvm.ai/tutorials/optimize/opt_gemm.html#sphx-glr-tutorials-optimize-opt-gemm-py)。类似地，可参考Vivado HLS优化GEMM的[方法]({% post_url 2020-03-11-vivado-hls %})。其中涉及到局部性(locality)的问题会详细进行分析。

<!--more-->

{% include prism-js.html %}

<!-- https://stackoverflow.com/questions/8988855/include-another-html-file-in-a-html-file -->
<!-- <div id="includedContent">
<script language="javascript">
    var code = $(function(){
      $("#includedContent").load("/files/programs/tvm_gemm_cpu.py");
    });
    document.getElementById("includedContent").innerHTML = code;
    console.log(code);
    console.log(hightlightElement(code));
</script>
</div> -->

## 朴素GEMM
我们可以将朴素GEMM，写成下列这种伪代码形式，用爱因斯坦求和记号([einsum](https://stackoverflow.com/questions/26089893/understanding-numpys-einsum))即$C_{ij}=A_{ik}B_{kj}$
```python
for (i, 0, M)
  for (j, 0, N)
    for (k, 0, K)
      C[i][j] += A[i][k] * B[k][j]
```

可先写出朴素的NumPy和TVM实现，并比较它们的运行时间。

<pre data-src="{{ site.baseurl }}/files/programs/tvm_gemm_cpu.py"></pre>

输出结果如下，可以看到numpy的速度（调用Intel MKL）是比裸GEMM实现$O(n^3)$要快得多的。
```
produce C {
  for (x, 0, 1024) {
    for (y, 0, 1024) {
      C[((x*1024) + y)] = 0f
      for (k, 0, 1024) {
        C[((x*1024) + y)] = (C[((x*1024) + y)] + (A[((x*1024) + k)]*B[((k*1024) + y)]))
      }
    }
  }
}

Numpy running time: 0.007936
Baseline: 2.890711
```

接下来我们仔细分析下其中的瓶颈。

## 循环重排(reordering)
注意到我们访问数据的模式，对于C和A矩阵来说，我们都是采用**逐行**遍历数据的方式，而对于B则是**逐列**遍历数据。

![traversal order](https://pic1.zhimg.com/v2-63824b31132c24f8a7d847c10a4f5ac4_b.jpg)

但是通常情况下，在计算机里我们采用的都是行优先(row-major)存储。如果一个cache line可以装8\*int(32B)，那么按行遍历（正Z型），可以保证每8个访存只有第1个元素miss；而按列遍历，很有可能读入的行数据没有用到就被驱逐出去了，miss rate为100\%。

![cache miss](https://pic3.zhimg.com/v2-90d70c9b7599df629979b392a60d9a5a_b.jpg)

故一个简单但极其有效的方式就是修改遍历顺序，即循环重排。
```python
for (i, 0, M)
  for (k, 0, K)
    for (j, 0, N)
      C[i][j] = A[i][k] * B[k][j]
```

计算结果显然是一样的，但是重排之后，B也变成了行遍历，进而提升了空间局部性，如下图。

![row traversal](https://pic4.zhimg.com/v2-a03f97b81e637e3357224d192c0de167_b.jpg)

我们分析下这种模式：
* 重复扫C数组K次，每次扫同一行（时间局部性好）
* A的时间局部性同样很高，因为`A[i][k]`被重复用了N次
* B则是确保了行优先(row-major)存储下的空间局部性

只需要在TVM中添加一行

```python
s[C].reorder(C.op.axis[0], k, C.op.axis[1])
```

即可实现循环重排。计算结果如下，可以看到k循环确实放到了中间层，并且速度提升了15倍！

```
produce C {
  for (x, 0, 1024) {
    for (y.init, 0, 1024) {
      C[((x*1024) + y.init)] = 0f
    }
    for (k, 0, 1024) {
      for (y, 0, 1024) {
        C[((x*1024) + y)] = (C[((x*1024) + y)] + (A[((x*1024) + k)]*B[((k*1024) + y)]))
      }
    }
  }
}

Opt1: 0.190684
```